---
{"dg-publish":true,"permalink":"/02/2402/02//","noteIcon":"","created":"2025-01-31T00:35","updated":"2025-07-01T13:38"}
---

# 1. 
精度1和0.999训练结果会有多少差别、
归纳法与演绎法
- [x] wang. deep learning for egfe computing application: astate-of-art survey.IEEE access,8,58322  [completion:: 2025-02-15]
- [x] arxiv:1706.03762(2017)  [completion:: 2025-02-15]
- [x] Nature Machine Intelligence,6,161-169(2024)大语言模型解决化学问题  [completion:: 2025-02-15]
# 2.方为
## 学习目标
- 化学体系中常演的描述符
- 监督学习、非监督学习、强化学习
- 损失函数、过拟合与欠拟合
- 数学模型
- 神经网络
### 参考资料
sklearn的user guide
pytorch的documentation
《线性代数与数据学习》[美]吉尔伯特·斯特朗 著，余志平 李铁夫 马辉 译，清华大学出版社
《简明线性代数》，丘维声，北京大学出版社
### 2.1.1 机器学习的基本范式
#### 监督学习
主要应用场景：回归与分类
**损失函数**：用来衡量模型预测值与训练集中实际值差别的函数：均方差；交叉熵（用于基于概率的分类，也可以在损失函数中给每个数据赋予任意权重）
**过拟合**：参数设置过多
    解决方法：正则化：在损失函数中增加对参数复杂度的惩罚项
    边际似然
    交叉验证：比较在训练集和测试集结果，如果训练集比较好，而测试集上比较查，就是一个很明显的overfitting标志
    early stop：在检测到误差增大时停止训练
    调整测试集：剔除误差大的样本
#### 非监督学习
有点像“推测”，比较主观，不同模型差别可能比较大
**维度缩减**：把高维的数据压缩成低维（有点像“画像”，把实物呈现在画纸上）
**聚类**：让机器根据数据本身的特点进行分类的方法，**与监督学习的分类不同**，很可能有不同答案
**关联规则学习**：抖音、“打字机猴子”chatGPT
**自动编码**：
#### 强化学习
像是训狗，对一定的行动进行奖励
### 2.1.2 常用数学模型
- 监督学习-线性回归
模型假设y对x线性相关：$\hat{y}=W^Tx+b$，求解$W,b$使损失函数小，可以得到解析表达式$(X^TX)^{-1}X^Ty$
- 监督学习-非线性回归
核函数（kernal）：用于度量空间中两点相似程度的函数
    常见的有：
    Gaussian kernel(RBF)
    Rational Quadratic kernel
    periodic kernel
核脊回归与高斯过程回归（KRR&GPR）
    模型根据点$x^*$与空间中所有点的相似程度进行预测：
    $$
\hat{y}=W^Tk+b
$$
- 监督学习-支持向量机（SVM）
寻找最优的d-l超频概念将属于两个类的数据分开
    硬边界与软边界
    可以用于手写汉字识别
    优点是模型简单，效果好，缺点是在复杂数据上效果不好
- 监督学习-决策树
# 第七周 段赛
问题
- [x] C-N偶联文章中：线性回归与ML的区别在哪  [completion:: 2025-02-15]