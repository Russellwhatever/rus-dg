---
{"dg-publish":true,"permalink":"/02/2501/07/08/","noteIcon":"","created":"2025-03-27T18:55","updated":"2025-07-01T13:38"}
---

![99 Attachment/Pasted image 20250327185544.png](/img/user/99%20Attachment/Pasted%20image%2020250327185544.png)
想要找到 q 以逼近 z|x，KL divergence: 
![99 Attachment/Pasted image 20250327185952.png](/img/user/99%20Attachment/Pasted%20image%2020250327185952.png) 
是衡量两个分布的距离。KL 本身其实是 taylor 展开的二阶余项
![99 Attachment/Pasted image 20250327190251.png](/img/user/99%20Attachment/Pasted%20image%2020250327190251.png)
$$
KL(q(z)||p(z|x))=\log p(x)-ELBO
$$
由于 $KL\geq_{0}$，$\log p(x)\geq ELBO$
优化的目的：最小化 KL 也就是最大化 ELBO
![99 Attachment/Pasted image 20250327190659.png](/img/user/99%20Attachment/Pasted%20image%2020250327190659.png)
# Mean-Field Variation Inference
拆分认为 
![99 Attachment/Pasted image 20250327191358.png](/img/user/99%20Attachment/Pasted%20image%2020250327191358.png)
## Deriving the Mean-Field Update
- Coordinate Ascent Approach
![99 Attachment/Pasted image 20250327191613.png](/img/user/99%20Attachment/Pasted%20image%2020250327191613.png)
相当于：先固定其他维，优化某维；然后依次优化
![99 Attachment/Pasted image 20250327191700.png](/img/user/99%20Attachment/Pasted%20image%2020250327191700.png)
其他固定后，$q_{i}$ 如上。
重复以上过程，不断优化，直到收敛，**即为**Mean-Field Algorithm

# 生成模型
## Manifold Hypothesis
PCA：
![99 Attachment/Pasted image 20250327193311.png](/img/user/99%20Attachment/Pasted%20image%2020250327193311.png)
先降维（乘上一个较短矩阵）再升维（乘高矩阵）
![99 Attachment/Pasted image 20250327193546.png](/img/user/99%20Attachment/Pasted%20image%2020250327193546.png)
![99 Attachment/Pasted image 20250327194240.png](/img/user/99%20Attachment/Pasted%20image%2020250327194240.png)
困境：latent 差一点就可能造成结果很大的误差
## VAE（variational auto encoder） - 解决上述问题
从直觉角度的推导：可以理解为均值+一个高斯的噪声，也可以理解为降维为球形
![99 Attachment/Pasted image 20250327200315.png](/img/user/99%20Attachment/Pasted%20image%2020250327200315.png)
![99 Attachment/Pasted image 20250327200719.png](/img/user/99%20Attachment/Pasted%20image%2020250327200719.png)
# VAE：贝叶斯 approach
无监督学习
![99 Attachment/Pasted image 20250327201538.png](/img/user/99%20Attachment/Pasted%20image%2020250327201538.png)
因此设计 loss：max $\log(p)$，仅有 x=d 的时候 delta =1
![99 Attachment/Pasted image 20250327201744.png](/img/user/99%20Attachment/Pasted%20image%2020250327201744.png)
因此加噪（同上一节，不过现在是另一种角度的推导）
然后用 Monte Calo，采很多个 z
但是还是不行：
    - 每个 z 都要计算，很慢
    - 可能结果会更差
![99 Attachment/Pasted image 20250327203316.png](/img/user/99%20Attachment/Pasted%20image%2020250327203316.png)
![99 Attachment/Pasted image 20250327203351.png](/img/user/99%20Attachment/Pasted%20image%2020250327203351.png)
![99 Attachment/Pasted image 20250327203509.png](/img/user/99%20Attachment/Pasted%20image%2020250327203509.png)
## 总结
VAE 生成的图像很糊 
![99 Attachment/Pasted image 20250327204436.png](/img/user/99%20Attachment/Pasted%20image%2020250327204436.png)
就变成图像的叠加了，而不是希望的 latent 的叠加
# 推导结果还是需要计算积分啊？
![99 Attachment/Pasted image 20250327205017.png](/img/user/99%20Attachment/Pasted%20image%2020250327205017.png)
![99 Attachment/Pasted image 20250327205131.png](/img/user/99%20Attachment/Pasted%20image%2020250327205131.png)
采到目标区域的概率很大，方差很小